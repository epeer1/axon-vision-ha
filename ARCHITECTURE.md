# Video Processing Pipeline - Architecture Design

## üèóÔ∏è System Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Streamer  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Detector   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Display   ‚îÇ
‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ
‚îÇ - Read Video‚îÇ    ‚îÇ - Motion    ‚îÇ    ‚îÇ - Draw      ‚îÇ
‚îÇ - Extract   ‚îÇ    ‚îÇ   Detection ‚îÇ    ‚îÇ - Blur      ‚îÇ
‚îÇ   Frames    ‚îÇ    ‚îÇ - Analysis  ‚îÇ    ‚îÇ - Show      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚ñ≤                   ‚ñ≤                   ‚ñ≤
      ‚îÇ                   ‚îÇ                   ‚îÇ
   Process 1           Process 2           Process 3
```

## üìÅ Repository Structure

```
AxonVisionHomeAssignment/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ assignment-description.md
‚îú‚îÄ‚îÄ ARCHITECTURE.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ 
‚îú‚îÄ‚îÄ # Phase Runners (Demo Each Development Stage)
‚îú‚îÄ‚îÄ phase_a_runner.py         # Basic pipeline demo
‚îú‚îÄ‚îÄ phase_b_runner.py         # Pipeline + motion blur demo
‚îú‚îÄ‚îÄ phase_c_runner.py         # Full system + auto-shutdown demo
‚îú‚îÄ‚îÄ 
‚îú‚îÄ‚îÄ # Process Services (Separate Processes)
‚îú‚îÄ‚îÄ streamer_process.py       # Video streaming service
‚îú‚îÄ‚îÄ detector_process.py       # Motion detection service  
‚îú‚îÄ‚îÄ display_process.py        # Display/rendering service
‚îú‚îÄ‚îÄ 
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ settings.py
‚îÇ   ‚îî‚îÄ‚îÄ communication.py
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base_component.py
‚îÇ   ‚îî‚îÄ‚îÄ data_models.py
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ streamer/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video_streamer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ frame_reader.py
‚îÇ   ‚îú‚îÄ‚îÄ detector/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ motion_detector.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ opencv_detector.py
‚îÇ   ‚îî‚îÄ‚îÄ display/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ video_display.py
‚îÇ       ‚îî‚îÄ‚îÄ frame_renderer.py
‚îú‚îÄ‚îÄ communication/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ zmq_manager.py
‚îÇ   ‚îú‚îÄ‚îÄ message_handler.py
‚îÇ   ‚îî‚îÄ‚îÄ protocol.py
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ logger.py
‚îÇ   ‚îú‚îÄ‚îÄ performance_monitor.py
‚îÇ   ‚îî‚îÄ‚îÄ config_loader.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_streamer.py
‚îÇ   ‚îú‚îÄ‚îÄ test_detector.py
‚îÇ   ‚îî‚îÄ‚îÄ test_display.py
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ People - 6387.mp4
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ phase_a.md
    ‚îú‚îÄ‚îÄ phase_b.md
    ‚îî‚îÄ‚îÄ phase_c.md
```

## üîß Component Architecture

### 1. Streamer Component
**Responsibilities:**
- Read video file frame by frame
- Control playback timing/FPS
- Send frames to Detector

**Interface:**
```python
class VideoStreamer:
    def __init__(self, video_path: str, target_fps: int)
    def start_streaming(self) -> None
    def stop_streaming(self) -> None
    def send_frame(self, frame: np.ndarray) -> bool
```

### 2. Detector Component
**Responsibilities:**
- Receive frames from Streamer
- Perform motion detection
- Send frame + detection data to Display

**Interface:**
```python
class MotionDetector:
    def __init__(self, detection_config: DetectionConfig)
    def process_frame(self, frame: np.ndarray) -> DetectionResult
    def start_detection(self) -> None
    def stop_detection(self) -> None
```

### 3. Display Component
**Responsibilities:**
- Receive frame + detection data
- Draw detections and timestamp
- Display video smoothly
- Handle blurring (Phase B)

**Interface:**
```python
class VideoDisplay:
    def __init__(self, display_config: DisplayConfig)
    def render_frame(self, frame: np.ndarray, detections: List[Detection]) -> None
    def add_timestamp(self, frame: np.ndarray) -> np.ndarray
    def apply_blur(self, frame: np.ndarray, regions: List[Region]) -> np.ndarray
```

## üîÑ Communication Strategy

### ‚≠ê **CHOSEN: ZeroMQ Sockets (Production-Grade)**
- **Pros**: High performance, optimized for video, non-blocking, industry standard
- **Cons**: External dependency (pip install pyzmq)
- **Use Case**: Production real-time video processing systems
- **Why**: Perfect for Axon's production infrastructure requirements

### Alternative Options:
- **Multiprocessing Queues**: Simple but serialization overhead for video frames
- **Shared Memory**: Fastest but complex synchronization
- **Named Pipes**: OS-specific, complex for cross-platform deployment

**Decision Rationale**: ZeroMQ is the industry standard for high-performance video processing pipelines, demonstrating production-ready architecture skills.

## üìä Data Models

### Frame Data
```python
@dataclass
class FrameData:
    frame_id: int
    timestamp: float
    frame: np.ndarray
    metadata: Dict[str, Any]
```

### Detection Result
```python
@dataclass
class DetectionResult:
    frame_id: int
    timestamp: float
    frame: np.ndarray
    detections: List[Detection]
    processing_time: float

@dataclass
class Detection:
    bbox: Tuple[int, int, int, int]  # x, y, w, h
    confidence: float
    detection_type: str
```

## ‚ö° Performance Considerations

### Timing & Synchronization
- **Frame Rate Control**: Maintain original video FPS
- **Buffer Management**: Prevent memory overflow with bounded queues
- **Backpressure**: Handle slow components gracefully

### Memory Optimization
- **Frame Sharing**: Use shared memory for large frames
- **Queue Size Limits**: Prevent unbounded memory growth
- **Garbage Collection**: Proper cleanup of processed frames

## üîÑ Phase Implementation Strategy

### Phase A: Core Pipeline
1. Implement basic IPC with queues
2. Create minimal viable components
3. Focus on smooth video playback
4. Basic motion detection integration

### Phase B: Motion Blur
1. Extend Display component
2. Add blur algorithms
3. Integrate with detection regions
4. Maintain performance

### Phase C: Auto Shutdown
1. Add shutdown signals
2. Graceful process termination
3. Resource cleanup
4. End-of-video detection

## üè∑Ô∏è Git Workflow

```bash
# Phase A
git checkout -b phase-a
# ... implement Phase A
git tag phase-a-v1.0
git push origin phase-a-v1.0

# Phase B  
git checkout -b phase-b
# ... implement Phase B
git tag phase-b-v1.0
git push origin phase-b-v1.0

# Phase C
git checkout -b phase-c
# ... implement Phase C
git tag phase-c-v1.0
git push origin phase-c-v1.0
```

## üß™ Testing Strategy

- **Unit Tests**: Each component individually
- **Integration Tests**: Component communication
- **Performance Tests**: FPS and latency measurements
- **End-to-End Tests**: Complete pipeline validation

## üìà Production-Grade Considerations

### Performance Optimization
- **Zero-copy operations** where possible with ZeroMQ
- **Asynchronous processing** to prevent blocking
- **Memory pool management** for frame buffers  
- **CPU/GPU utilization monitoring**

### Monitoring & Logging
- **Real-time metrics**: FPS, latency, memory usage, CPU load
- **Component health**: Process status, message queue depths
- **Error tracking**: Exception handling with stack traces
- **Performance profiling**: Bottleneck identification

### Production Reliability
- **Graceful error recovery**: Component restart on failure
- **Backpressure handling**: Prevent memory overflow
- **Configuration management**: Runtime parameter adjustment
- **Resource cleanup**: Proper shutdown procedures

### Scalability Design
- **Edge deployment ready**: Optimized for limited resources
- **Cloud scaling patterns**: Multi-instance coordination
- **Hardware abstraction**: Camera/display device independence
- **Network resilience**: Handle connectivity issues 

## üéØ **Final Deliverable: Real-Time Video Pipeline Viewer**

**What we're building:**
- A **simple real-time video viewer** that demonstrates the multi-process pipeline
- Uses `cv2.imshow()` for display (no complex UI needed)
- **Focus**: Proving the 3-process architecture works smoothly
- **Goal**: Show motion detection, blurring, and timestamps in real-time

**User Experience:**
```
User runs: python main.py
‚Üí Video window opens showing:
  - Original video with motion detection boxes
  - Timestamp in top-left corner  
  - Smooth playback (matching original FPS)
  - Blurred motion areas (Phase B)
  - Auto-closes when video ends (Phase C)
``` 